{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da0af39c",
   "metadata": {
    "papermill": {
     "duration": 0.003053,
     "end_time": "2023-11-09T18:28:24.584820",
     "exception": false,
     "start_time": "2023-11-09T18:28:24.581767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Project Part 1\n",
    "\n",
    "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/sgeinitz/CS39AA-project/blob/main/project_part1.ipynb)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgeinitz/CS39AA-project/blob/main/project_part1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2839e4f",
   "metadata": {
    "papermill": {
     "duration": 0.00416,
     "end_time": "2023-11-09T18:28:24.591565",
     "exception": false,
     "start_time": "2023-11-09T18:28:24.587405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Introduction/Background\n",
    "\n",
    "_In this section you will describe (in English) the dataset you are using as well as the NLP problem it deals with. For example, if you are planning to use the Twitter Natural Disaster dataset, then you will describe what the data and where it came as if you were explaining it to someone who does not know anything about the data. You will then describe how this is a __text classification__ problem, and that the labels are binary (e.g. a tweet either refers to a genuine/real natural disaster, or it does not)._ \n",
    "\n",
    "_Overall, this should be about a paragraph of text that could be read by someone outside of our class, and they could still understand what it is your project is doing._ \n",
    "\n",
    "_Note that you should __not__ simply write one sentence stating, \"This project is base on the Kaggle competition: Predicting Natural Disasters with Twitter._\"\n",
    "\n",
    "_If you instead are planning to do a more research-oriented or applied type of project, then describe what it is that you plan to do._\n",
    "\n",
    "_If it is research, then what do you want to understand/explain better?_\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The purpose of this project is to explore the effects of different hyperparameters, in terms of accuracy, on their respective models. I will start with random forest and compare it side by side, or progress to, other models. It should be noted this is an deeper analysis of internal hyperperameraters and may or may not delve into hidden layers, dropout rates, etc., and is purely informational. The results from this project are not meant to be used as a final model and are more intended to be used as a potential starting point when building Machine Learning or Deep Learning models.\n",
    "\n",
    "The chosen dataset for this project is \"Starbucks Reviews Dataset\" published by Harshal H on kaggle at https://www.kaggle.com/datasets/harshalhonde/starbucks-reviews-dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67b9730",
   "metadata": {
    "papermill": {
     "duration": 0.002403,
     "end_time": "2023-11-09T18:28:24.596333",
     "exception": false,
     "start_time": "2023-11-09T18:28:24.593930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "_You will now load the dataset and carry out some exploratory data analysis steps to better understand what text data looks like. See the examples from class on 10/. The following links provide some good resources of exploratory analyses of text data with Python._\n",
    "\n",
    "\n",
    "* https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools\n",
    "* https://regenerativetoday.com/exploratory-data-analysis-of-text-data-including-visualization-and-sentiment-analysis/\n",
    "* https://medium.com/swlh/text-summarization-guide-exploratory-data-analysis-on-text-data-4e22ce2dd6ad  \n",
    "* https://www.kdnuggets.com/2019/05/complete-exploratory-data-analysis-visualization-text-data.html  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "200e90df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T18:28:24.604896Z",
     "iopub.status.busy": "2023-11-09T18:28:24.604542Z",
     "iopub.status.idle": "2023-11-09T18:28:25.412964Z",
     "shell.execute_reply": "2023-11-09T18:28:25.411299Z"
    },
    "papermill": {
     "duration": 0.816557,
     "end_time": "2023-11-09T18:28:25.416061",
     "exception": false,
     "start_time": "2023-11-09T18:28:24.599504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/starbucks-reviews-dataset/reviews_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe3977c",
   "metadata": {
    "papermill": {
     "duration": 0.002538,
     "end_time": "2023-11-09T18:28:25.421592",
     "exception": false,
     "start_time": "2023-11-09T18:28:25.419054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First we will open up the dataset to take a peek at the contents. The code above will give us the filepath to the dataset, and the code below prints out the first few entries of the dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6229e721",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T18:28:25.429350Z",
     "iopub.status.busy": "2023-11-09T18:28:25.428585Z",
     "iopub.status.idle": "2023-11-09T18:28:25.481816Z",
     "shell.execute_reply": "2023-11-09T18:28:25.480831Z"
    },
    "papermill": {
     "duration": 0.059582,
     "end_time": "2023-11-09T18:28:25.484052",
     "exception": false,
     "start_time": "2023-11-09T18:28:25.424470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Image_Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Helen</td>\n",
       "      <td>Wichita Falls, TX</td>\n",
       "      <td>Reviewed Sept. 13, 2023</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Amber and LaDonna at the Starbucks on Southwes...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Courtney</td>\n",
       "      <td>Apopka, FL</td>\n",
       "      <td>Reviewed July 16, 2023</td>\n",
       "      <td>5.0</td>\n",
       "      <td>** at the Starbucks by the fire station on 436...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daynelle</td>\n",
       "      <td>Cranberry Twp, PA</td>\n",
       "      <td>Reviewed July 5, 2023</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I just wanted to go out of my way to recognize...</td>\n",
       "      <td>['https://media.consumeraffairs.com/files/cach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taylor</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Reviewed May 26, 2023</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Me and my friend were at Starbucks and my card...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tenessa</td>\n",
       "      <td>Gresham, OR</td>\n",
       "      <td>Reviewed Jan. 22, 2023</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I’m on this kick of drinking 5 cups of warm wa...</td>\n",
       "      <td>['https://media.consumeraffairs.com/files/cach...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name           location                     Date  Rating  \\\n",
       "0     Helen  Wichita Falls, TX  Reviewed Sept. 13, 2023     5.0   \n",
       "1  Courtney         Apopka, FL   Reviewed July 16, 2023     5.0   \n",
       "2  Daynelle  Cranberry Twp, PA    Reviewed July 5, 2023     5.0   \n",
       "3    Taylor        Seattle, WA    Reviewed May 26, 2023     5.0   \n",
       "4   Tenessa        Gresham, OR   Reviewed Jan. 22, 2023     5.0   \n",
       "\n",
       "                                              Review  \\\n",
       "0  Amber and LaDonna at the Starbucks on Southwes...   \n",
       "1  ** at the Starbucks by the fire station on 436...   \n",
       "2  I just wanted to go out of my way to recognize...   \n",
       "3  Me and my friend were at Starbucks and my card...   \n",
       "4  I’m on this kick of drinking 5 cups of warm wa...   \n",
       "\n",
       "                                         Image_Links  \n",
       "0                                      ['No Images']  \n",
       "1                                      ['No Images']  \n",
       "2  ['https://media.consumeraffairs.com/files/cach...  \n",
       "3                                      ['No Images']  \n",
       "4  ['https://media.consumeraffairs.com/files/cach...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_path = '/kaggle/input/starbucks-reviews-dataset/'\n",
    "training_data_file = 'reviews_data.csv'\n",
    "df = pd.read_csv(input_data_path + training_data_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa21b7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T18:28:25.491917Z",
     "iopub.status.busy": "2023-11-09T18:28:25.491381Z",
     "iopub.status.idle": "2023-11-09T18:28:25.519360Z",
     "shell.execute_reply": "2023-11-09T18:28:25.517715Z"
    },
    "papermill": {
     "duration": 0.034664,
     "end_time": "2023-11-09T18:28:25.521968",
     "exception": false,
     "start_time": "2023-11-09T18:28:25.487304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 850 entries, 0 to 849\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   name         850 non-null    object \n",
      " 1   location     850 non-null    object \n",
      " 2   Date         850 non-null    object \n",
      " 3   Rating       705 non-null    float64\n",
      " 4   Review       850 non-null    object \n",
      " 5   Image_Links  850 non-null    object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 40.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5553389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T18:28:25.529554Z",
     "iopub.status.busy": "2023-11-09T18:28:25.529191Z",
     "iopub.status.idle": "2023-11-09T18:28:25.537271Z",
     "shell.execute_reply": "2023-11-09T18:28:25.535664Z"
    },
    "papermill": {
     "duration": 0.014967,
     "end_time": "2023-11-09T18:28:25.539885",
     "exception": false,
     "start_time": "2023-11-09T18:28:25.524918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7973c10a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T18:28:25.548131Z",
     "iopub.status.busy": "2023-11-09T18:28:25.547703Z",
     "iopub.status.idle": "2023-11-09T18:28:25.557934Z",
     "shell.execute_reply": "2023-11-09T18:28:25.556879Z"
    },
    "papermill": {
     "duration": 0.01689,
     "end_time": "2023-11-09T18:28:25.560118",
     "exception": false,
     "start_time": "2023-11-09T18:28:25.543228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'location', 'Date', 'Rating', 'Review', 'Image_Links']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb185a28",
   "metadata": {
    "papermill": {
     "duration": 0.002721,
     "end_time": "2023-11-09T18:28:25.566130",
     "exception": false,
     "start_time": "2023-11-09T18:28:25.563409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "The first peek into the dataset shows us quite a bit. First, the data consists of 6 columns as listed above. For the purposes of this model the only columns that will be used are 'Rating' and 'Review'as they are the two columns that give the relevant data. 'Name', 'location', and 'Image_Links' are irrellevent to what we want to look at, and though 'Date' may yeild something useful, perhaps there was a trend towards positive or negative reviews depending on the year, it is also not needed as that is beyond the scope of this particular project. \n",
    "Second, there are 850 entries in the dataset, of which there are 705 non-null values in the ratings column. The null data will be removed so that there is less chance that bad data is introduced, potentially decreasing the models predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.515822,
   "end_time": "2023-11-09T18:28:25.988168",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-09T18:28:20.472346",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
