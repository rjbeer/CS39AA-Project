{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"bb3398f4b21c7b026dd5874af3f954bf25f1e8ff81e25d82a94abcbbaacf760b"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project Part 1\n\n[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/sgeinitz/CS39AA-project/blob/main/project_part1.ipynb)\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgeinitz/CS39AA-project/blob/main/project_part1.ipynb)\n\nThis notebook is intended to serve as a template to complete Part 1 of the projects. Feel free to modify this notebook as needed, but be sure to have the two main parts, a) a introductory proposal section describing what it is your doing to do and where the dataset originates, and b) an exploratory analysis section that has the histograms, charts, tables, etc. that are the output from your exploratory analysis. \n\n__Note you will want to remove the text above, and in the markdown cells below, and replace it with your own text describing the dataset, task, exploratory steps, etc.__","metadata":{}},{"cell_type":"markdown","source":"## 1. Introduction/Background\n\n_In this section you will describe (in English) the dataset you are using as well as the NLP problem it deals with. For example, if you are planning to use the Twitter Natural Disaster dataset, then you will describe what the data and where it came as if you were explaining it to someone who does not know anything about the data. You will then describe how this is a __text classification__ problem, and that the labels are binary (e.g. a tweet either refers to a genuine/real natural disaster, or it does not)._ \n\n_Overall, this should be about a paragraph of text that could be read by someone outside of our class, and they could still understand what it is your project is doing._ \n\n_Note that you should __not__ simply write one sentence stating, \"This project is base on the Kaggle competition: Predicting Natural Disasters with Twitter._\"\n\n_If you instead are planning to do a more research-oriented or applied type of project, then describe what it is that you plan to do._\n\n_If it is research, then what do you want to understand/explain better?_\n\n\n## Introduction\n\nThe purpose of this project is to explore the effects of different hyperparameters, in terms of accuracy, on their respective models. I will start with random forest and compare it side by side, or progress to, other models. It should be noted this is an deeper analysis of internal hyperperameraters and may or may not delve into hidden layers, dropout rates, etc., and is purely informational. The results from this project are not meant to be used as a final model and are more intended to be used as a potential starting point when building Machine Learning or Deep Learning models.\n\nThe chosen dataset for this project is \"Starbucks Reviews Dataset\" published by Harshal H on kaggle at https://www.kaggle.com/datasets/harshalhonde/starbucks-reviews-dataset.","metadata":{}},{"cell_type":"markdown","source":"## 2. Exploratory Data Analysis\n\n_You will now load the dataset and carry out some exploratory data analysis steps to better understand what text data looks like. See the examples from class on 10/. The following links provide some good resources of exploratory analyses of text data with Python._\n\n\n* https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools\n* https://regenerativetoday.com/exploratory-data-analysis-of-text-data-including-visualization-and-sentiment-analysis/\n* https://medium.com/swlh/text-summarization-guide-exploratory-data-analysis-on-text-data-4e22ce2dd6ad  \n* https://www.kdnuggets.com/2019/05/complete-exploratory-data-analysis-visualization-text-data.html  \n\n\n","metadata":{}},{"cell_type":"code","source":"# import all of the python modules/packages you'll need here\nimport pandas as pd\nimport numpy as np\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# ...","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:26:30.726511Z","iopub.execute_input":"2023-11-09T17:26:30.727279Z","iopub.status.idle":"2023-11-09T17:26:31.208324Z","shell.execute_reply.started":"2023-11-09T17:26:30.727233Z","shell.execute_reply":"2023-11-09T17:26:31.206979Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/starbucks-reviews-dataset/reviews_data.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"First we will open up the dataset to take a peek at the contents. The code above will give us the filepath to the dataset, and the code below prints out the first few entries of the dataset...","metadata":{}},{"cell_type":"code","source":"input_data_path = '/kaggle/input/starbucks-reviews-dataset/'\ntraining_data_file = 'reviews_data.csv'\ndf = pd.read_csv(input_data_path + training_data_file)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:32:55.355447Z","iopub.execute_input":"2023-11-09T17:32:55.355878Z","iopub.status.idle":"2023-11-09T17:32:55.390077Z","shell.execute_reply.started":"2023-11-09T17:32:55.355845Z","shell.execute_reply":"2023-11-09T17:32:55.388812Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       name           location                     Date  Rating  \\\n0     Helen  Wichita Falls, TX  Reviewed Sept. 13, 2023     5.0   \n1  Courtney         Apopka, FL   Reviewed July 16, 2023     5.0   \n2  Daynelle  Cranberry Twp, PA    Reviewed July 5, 2023     5.0   \n3    Taylor        Seattle, WA    Reviewed May 26, 2023     5.0   \n4   Tenessa        Gresham, OR   Reviewed Jan. 22, 2023     5.0   \n\n                                              Review  \\\n0  Amber and LaDonna at the Starbucks on Southwes...   \n1  ** at the Starbucks by the fire station on 436...   \n2  I just wanted to go out of my way to recognize...   \n3  Me and my friend were at Starbucks and my card...   \n4  I’m on this kick of drinking 5 cups of warm wa...   \n\n                                         Image_Links  \n0                                      ['No Images']  \n1                                      ['No Images']  \n2  ['https://media.consumeraffairs.com/files/cach...  \n3                                      ['No Images']  \n4  ['https://media.consumeraffairs.com/files/cach...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>location</th>\n      <th>Date</th>\n      <th>Rating</th>\n      <th>Review</th>\n      <th>Image_Links</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Helen</td>\n      <td>Wichita Falls, TX</td>\n      <td>Reviewed Sept. 13, 2023</td>\n      <td>5.0</td>\n      <td>Amber and LaDonna at the Starbucks on Southwes...</td>\n      <td>['No Images']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Courtney</td>\n      <td>Apopka, FL</td>\n      <td>Reviewed July 16, 2023</td>\n      <td>5.0</td>\n      <td>** at the Starbucks by the fire station on 436...</td>\n      <td>['No Images']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Daynelle</td>\n      <td>Cranberry Twp, PA</td>\n      <td>Reviewed July 5, 2023</td>\n      <td>5.0</td>\n      <td>I just wanted to go out of my way to recognize...</td>\n      <td>['https://media.consumeraffairs.com/files/cach...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Taylor</td>\n      <td>Seattle, WA</td>\n      <td>Reviewed May 26, 2023</td>\n      <td>5.0</td>\n      <td>Me and my friend were at Starbucks and my card...</td>\n      <td>['No Images']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Tenessa</td>\n      <td>Gresham, OR</td>\n      <td>Reviewed Jan. 22, 2023</td>\n      <td>5.0</td>\n      <td>I’m on this kick of drinking 5 cups of warm wa...</td>\n      <td>['https://media.consumeraffairs.com/files/cach...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:34:38.559530Z","iopub.execute_input":"2023-11-09T17:34:38.559967Z","iopub.status.idle":"2023-11-09T17:34:38.575230Z","shell.execute_reply.started":"2023-11-09T17:34:38.559934Z","shell.execute_reply":"2023-11-09T17:34:38.573753Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 850 entries, 0 to 849\nData columns (total 6 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   name         850 non-null    object \n 1   location     850 non-null    object \n 2   Date         850 non-null    object \n 3   Rating       705 non-null    float64\n 4   Review       850 non-null    object \n 5   Image_Links  850 non-null    object \ndtypes: float64(1), object(5)\nmemory usage: 40.0+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:35:09.058654Z","iopub.execute_input":"2023-11-09T17:35:09.059197Z","iopub.status.idle":"2023-11-09T17:35:09.066656Z","shell.execute_reply.started":"2023-11-09T17:35:09.059154Z","shell.execute_reply":"2023-11-09T17:35:09.065366Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(850, 6)"},"metadata":{}}]},{"cell_type":"code","source":"df.columns.tolist()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T17:38:12.489430Z","iopub.execute_input":"2023-11-09T17:38:12.490722Z","iopub.status.idle":"2023-11-09T17:38:12.499487Z","shell.execute_reply.started":"2023-11-09T17:38:12.490672Z","shell.execute_reply":"2023-11-09T17:38:12.498190Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['name', 'location', 'Date', 'Rating', 'Review', 'Image_Links']"},"metadata":{}}]},{"cell_type":"markdown","source":"The first peek into the dataset shows us quite a bit. First, the data consists of 6 columns as listed above. For the purposes of this model the only columns that will be used are 'Rating' and 'Review'as they are the two columns that give the relevant data. 'Name', 'location', and 'Image_Links' are irrellevent to what we want to look at, and though 'Date' may yeild something useful, perhaps there was a trend towards positive or negative reviews depending on the year, it is also not needed as that is beyond the scope of this particular project. \nSecond, there are 850 entries in the dataset, of which there are 705 non-null values in the ratings column. The null data will be removed so that there is less chance that bad data is introduced, potentially decreasing the models predictions.","metadata":{}}]}